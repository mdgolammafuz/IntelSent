artifacts_dir: artifacts

embedding:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  device: cpu  # use "cuda" or "mps" if you truly have them inside the container

retrieval:
  top_k: 10
  max_k: 10

generation:
  max_context_chars: 8000
  model: gpt-4o-mini
  use_openai: false

rerank:
  enabled: false
  model_name: cross-encoder/ms-marco-MiniLM-L-6-v2

pgvector:
  enabled: true
  # IMPORTANT: inside docker, connect to the service name, not localhost
  conn: postgresql://intel:intel@pgvector:5432/intelrag
  table: chunks
  text_col: text
