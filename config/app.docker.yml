# config/app.docker.yml  (mounted as /app/config/app.yaml)
artifacts_dir: artifacts

embedding:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  device: cpu

retrieval:
  top_k: 5
  max_k: 20

generation:
  max_context_chars: 6000
  model: gpt-4o-mini
  use_openai: false

rerank:
  enabled: false
  model_name: cross-encoder/ms-marco-MiniLM-L-6-v2

# NEW: provide BOTH shapes so whichever the code uses will be pgvector, not localhost
db:
  conn_str: postgresql://intel:intel@pgvector:5432/intelrag

pgvector:
  enabled: true
  conn: postgresql://intel:intel@pgvector:5432/intelrag
  table: chunks
  text_col: content
